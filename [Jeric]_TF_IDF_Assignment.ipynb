{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Jeric] TF-IDF Assignment ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Task 1: Build a TF-IDF Vectorizer </h3>"
      ],
      "metadata": {
        "id": "JQVSGgSJ7Kb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "8Zf6d_vWqS3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "metadata": {
        "id": "C8lnZmzArbz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define fit function to identify unqiue words in dataset\n",
        "# from assignment reference: https://colab.research.google.com/drive/1Y_K1iQV_wv7Z7I63axwMQJp1XJzgoF1s#scrollTo=vWqqbym-gA9I\n",
        "\n",
        "def fit(dataset):    \n",
        "    unique_words = set()\n",
        "    # check if its list data type\n",
        "    if isinstance(dataset, (list,)):\n",
        "        for row in dataset: # for each doc in the dataset\n",
        "            for word in row.split(\" \"): # convert a string into list of words and for each word\n",
        "                if len(word) < 2: # skip punctuation\n",
        "                    continue\n",
        "                unique_words.add(word)\n",
        "        unique_words = sorted(list(unique_words))\n",
        "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "        \n",
        "        return vocab\n",
        "    else:\n",
        "        print(\"you need to pass list of sentence\")"
      ],
      "metadata": {
        "id": "Ny7G8jUdquS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(fit(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiCKw-Qireck",
        "outputId": "f32d5413-1f10-40c1-f06c-4ce797e011f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to calculate IDF values for each word\n",
        "# https://analyticsindiamag.com/hands-on-implementation-of-tf-idf-from-scratch-in-python/\n",
        "# https://www.askpython.com/python/examples/tf-idf-model-from-scratch\n",
        "# https://stackabuse.com/python-for-nlp-creating-tf-idf-model-from-scratch/\n",
        "\n",
        "def IDF(corpus, unique_words):\n",
        "  idf_dict = {}\n",
        "  N = len(corpus) # no. of docs in corpus\n",
        "  for word in unique_words: # for each word in vocab\n",
        "    count = 0\n",
        "    for row in corpus: # for each doc in dataset\n",
        "      if word in row.split(): # convert a string into a list of words and if word exists in list, add 1 to count\n",
        "        count = count+1\n",
        "      idf_dict[word] = (math.log((1+N)/(count+1)))+1 # compute IDF value for each word\n",
        "  return idf_dict "
      ],
      "metadata": {
        "id": "xCYJkVoHmujG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = fit(corpus)\n",
        "\n",
        "IDF(corpus, unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nZGQZT6uzlA",
        "outputId": "9f081222-d967-4a70-f187-95a83aeb2d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1.916290731874155,\n",
              " 'document': 1.2231435513142097,\n",
              " 'first': 1.5108256237659907,\n",
              " 'is': 1.0,\n",
              " 'one': 1.916290731874155,\n",
              " 'second': 1.916290731874155,\n",
              " 'the': 1.0,\n",
              " 'third': 1.916290731874155,\n",
              " 'this': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf_values = IDF(corpus, unique_words)\n",
        "print(idf_values)\n",
        "# print(list(idf_values.keys()))\n",
        "# print(list(idf_values.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2b9-PFgwvQX",
        "outputId": "7a0d6df8-1b23-4eae-b008-742e89ffbe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1.916290731874155, 'document': 1.2231435513142097, 'first': 1.5108256237659907, 'is': 1.0, 'one': 1.916290731874155, 'second': 1.916290731874155, 'the': 1.0, 'third': 1.916290731874155, 'this': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to create a sparse matrix representation with TF-IDF values for each doc and unique word\n",
        "# https://analyticsindiamag.com/hands-on-implementation-of-tf-idf-from-scratch-in-python/\n",
        "# https://www.askpython.com/python/examples/tf-idf-model-from-scratch\n",
        "# https://stackabuse.com/python-for-nlp-creating-tf-idf-model-from-scratch/\n",
        "\n",
        "def transform(corpus,vocabulary,idf_values):\n",
        "     sparse_matrix = csr_matrix( (len(corpus), len(vocabulary)), dtype=np.float64) # create blank matrix with size N (no. of docs) x D (no. of unique words) with float data type\n",
        "     for row in range(0,len(corpus)): # for each doc in corpus\n",
        "       number_of_words_in_doc = Counter(corpus[row].split()) # create dict of words and its count for each doc\n",
        "       \n",
        "       # for each word in doc, if word exists in vocabulary, calculate TF-IDF and store in matrix\n",
        "       for word in corpus[row].split(): \n",
        "           if word in list(vocabulary.keys()):\n",
        "               tf_idf_value = (number_of_words_in_doc[word]/len(corpus[row].split())) * (idf_values[word])\n",
        "               sparse_matrix[row,vocabulary[word]] = tf_idf_value\n",
        "     \n",
        "     print(normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False))\n",
        "     output = normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
        "     return output"
      ],
      "metadata": {
        "id": "7aOHgE4V9Cyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = transform(corpus,unique_words,idf_values)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV5H0beCDDUX",
        "outputId": "759b5a2f-e85b-4547-de9b-37fb93a83ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "  (1, 1)\t0.6876235979836937\n",
            "  (1, 3)\t0.2810886740337529\n",
            "  (1, 5)\t0.5386476208856762\n",
            "  (1, 6)\t0.2810886740337529\n",
            "  (1, 8)\t0.2810886740337529\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.4697913855799205\n",
            "  (3, 2)\t0.580285823684436\n",
            "  (3, 3)\t0.3840852409148149\n",
            "  (3, 6)\t0.3840852409148149\n",
            "  (3, 8)\t0.3840852409148149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 21 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape # 4 documents and 9 unique words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tfEwf1Sz7Sb",
        "outputId": "3d6c21dc-06b3-4797-e43f-32af1481efa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Compare to sklearn implementation </h4>"
      ],
      "metadata": {
        "id": "JuW-cP899zaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "v_matrix= vectorizer.fit_transform(corpus)\n",
        "print(v_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKum2vDI-URh",
        "outputId": "192a32fe-1984-4c20-c1b2-54b4c1bcbe33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 8)\t0.38408524091481483\n",
            "  (1, 5)\t0.5386476208856763\n",
            "  (1, 1)\t0.6876235979836938\n",
            "  (1, 6)\t0.281088674033753\n",
            "  (1, 3)\t0.281088674033753\n",
            "  (1, 8)\t0.281088674033753\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.46979138557992045\n",
            "  (3, 2)\t0.5802858236844359\n",
            "  (3, 6)\t0.38408524091481483\n",
            "  (3, 3)\t0.38408524091481483\n",
            "  (3, 8)\t0.38408524091481483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sparse representation to dense matrix\n",
        "v_matrix.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXHWc8RBA3a-",
        "outputId": "ac710331-5563-4d7f-ceb1-67298429bd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524],\n",
              "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
              "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
              "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
              "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
              "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
              "        0.        , 0.38408524, 0.        , 0.38408524]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy98K0OgGy2J",
        "outputId": "1ce31543-dd9b-4b34-cae8-1e639c476f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo2oclTX-BKz",
        "outputId": "aa465de4-7e1b-4fee-a240-c55c5d9da343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The result from custom implementation closely resembles the sklearn implementation."
      ],
      "metadata": {
        "id": "anVdX1KX-nNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Task 2: Implement max features functionality for TF-IDF Vectorizer </h3>\n",
        "Vocabulary will contain only 50 terms with top idf scores"
      ],
      "metadata": {
        "id": "jCoXfSIe-GwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify top N words according to IDF values\n",
        "# https://stackoverflow.com/questions/38218501/python-get-top-n-keys-with-value-as-dictionary\n",
        "\n",
        "def get_top_words(data, n=3):\n",
        "    top = sorted(data.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "    return dict(top)"
      ],
      "metadata": {
        "id": "6vn1rVW-ePvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on Task 1 vocab idf values\n",
        "get_top_words(idf_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LntuxfCeZU-",
        "outputId": "1f6ea983-e24e-422a-f112-4e00234aacf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1.916290731874155,\n",
              " 'one': 1.916290731874155,\n",
              " 'second': 1.916290731874155}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cleaned_strings pickle file provided\n",
        "\n",
        "import pickle\n",
        "with open('cleaned_strings', 'rb') as f:\n",
        "    corpus = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ],
      "metadata": {
        "id": "Znf0i9zfJfvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b34a2ad-defe-4ced-e111-f010727ea928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run fit, IDF and get top words function as defined above\n",
        "unique_words = fit(corpus)\n",
        "idf_values = IDF(corpus, unique_words)\n",
        "top50_idf = get_top_words(idf_values, n=50)"
      ],
      "metadata": {
        "id": "N6PnQF0jeFIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the no. of words in top50_idf dict\n",
        "len(top50_idf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9md4r5VtftLk",
        "outputId": "fd16e622-fb0a-492a-d989-8c28595ee27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the no. of words in vocab dict - there is a need to filter list of unique words\n",
        "len(unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVxIrRRQgc5b",
        "outputId": "b33a4bb1-a9a3-479c-f1ed-cc6fd780ae2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2886"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter vocab to only include the top 50 words based on IDF scores\n",
        "# https://stackoverflow.com/questions/6827834/how-to-filter-a-dict-to-contain-only-keys-in-a-given-list\n",
        "# https://stackoverflow.com/questions/30661990/how-to-filter-python-dictionary-by-another-dictionary\n",
        "\n",
        "keys = list(top50_idf.keys())\n",
        "filtered_vocab = dict((k, unique_words[k]) for k in keys if k in unique_words)\n",
        "len(filtered_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTKXvonNjDUB",
        "outputId": "00cfecb2-8d9e-415c-b10b-f7f661cdce67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random check post filter\n",
        "list(filtered_vocab.items())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4nA2eCE0yAi",
        "outputId": "c5ba69b6-8d34-402c-aa3d-521dc0b77d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('aailiyah', 0),\n",
              " ('abandoned', 1),\n",
              " ('abroad', 3),\n",
              " ('abstruse', 5),\n",
              " ('academy', 7),\n",
              " ('accents', 8),\n",
              " ('accessible', 9),\n",
              " ('acclaimed', 10),\n",
              " ('accolades', 11),\n",
              " ('accurate', 12)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset index\n",
        "filtered_vocab = {j:i for i,j in enumerate(filtered_vocab)}\n",
        "list(filtered_vocab.items())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqC-PA6B15jo",
        "outputId": "8d168d7c-4f0c-4576-e0b6-0c7cf8ec90c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('aailiyah', 0),\n",
              " ('abandoned', 1),\n",
              " ('abroad', 2),\n",
              " ('abstruse', 3),\n",
              " ('academy', 4),\n",
              " ('accents', 5),\n",
              " ('accessible', 6),\n",
              " ('acclaimed', 7),\n",
              " ('accolades', 8),\n",
              " ('accurate', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return matrix with TF-IDF scores for first doc in corpus\n",
        "output = transform(corpus,filtered_vocab,top50_idf)\n",
        "output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3w0PDSL15mZ",
        "outputId": "16496cf1-155c-4e64-8851-2a42046b9815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 30)\t1.0\n",
            "  (68, 24)\t1.0\n",
            "  (72, 29)\t1.0\n",
            "  (74, 31)\t1.0\n",
            "  (119, 33)\t1.0\n",
            "  (135, 3)\t0.37796447300922725\n",
            "  (135, 10)\t0.37796447300922725\n",
            "  (135, 18)\t0.37796447300922725\n",
            "  (135, 20)\t0.37796447300922725\n",
            "  (135, 36)\t0.37796447300922725\n",
            "  (135, 40)\t0.37796447300922725\n",
            "  (135, 41)\t0.37796447300922725\n",
            "  (176, 49)\t1.0\n",
            "  (181, 13)\t1.0\n",
            "  (192, 21)\t1.0\n",
            "  (193, 23)\t1.0\n",
            "  (216, 2)\t1.0\n",
            "  (222, 47)\t1.0\n",
            "  (225, 19)\t1.0\n",
            "  (227, 17)\t1.0\n",
            "  (241, 44)\t1.0\n",
            "  (270, 1)\t1.0\n",
            "  (290, 25)\t1.0\n",
            "  (333, 26)\t1.0\n",
            "  (334, 15)\t1.0\n",
            "  (341, 43)\t1.0\n",
            "  (344, 42)\t1.0\n",
            "  (348, 8)\t1.0\n",
            "  (377, 37)\t1.0\n",
            "  (409, 5)\t1.0\n",
            "  (430, 39)\t1.0\n",
            "  (457, 45)\t1.0\n",
            "  (461, 4)\t1.0\n",
            "  (465, 38)\t1.0\n",
            "  (475, 35)\t1.0\n",
            "  (493, 6)\t1.0\n",
            "  (500, 48)\t1.0\n",
            "  (548, 0)\t0.7071067811865475\n",
            "  (548, 32)\t0.7071067811865475\n",
            "  (608, 14)\t1.0\n",
            "  (612, 11)\t1.0\n",
            "  (620, 46)\t1.0\n",
            "  (632, 7)\t1.0\n",
            "  (644, 12)\t0.7071067811865475\n",
            "  (644, 27)\t0.7071067811865475\n",
            "  (664, 28)\t1.0\n",
            "  (667, 22)\t1.0\n",
            "  (691, 34)\t1.0\n",
            "  (697, 9)\t1.0\n",
            "  (722, 16)\t1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x50 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape # 746 docs in corpus and 50 words in vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZsPPbe8234y",
        "outputId": "6e2886bc-1f35-41d5-b995-7db46ff38749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(746, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brQN2RreBYcz",
        "outputId": "ee76a1a7-ac91-4e47-da87-d186293e9ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0].toarray().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfxDUkUBb1f",
        "outputId": "4dbfcec2-6221-4c47-946c-942bd0f37e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The result from custom implementation returns a sparse representation matrix of shape (746,50), matching the no. of docs in dataset and no. of words in vocabulary."
      ],
      "metadata": {
        "id": "zpJT-ypRuS7p"
      }
    }
  ]
}